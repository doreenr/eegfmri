{
 "metadata": {
  "name": "Step_1_Data_Preparation"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Welcome to pylab, a matplotlib-based Python environment [backend: module://IPython.kernel.zmq.pylab.backend_inline].\n",
        "For more information, type 'help(pylab)'.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file remove.py\n",
      "\n",
      "def remove(lister, val):\n",
      "   return [value for value in lister if value != val]\n",
      "\n",
      "def remove_range(lister, val):\n",
      "   return [value for value in lister if value < val]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing remove.py\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pylab as plt\n",
      "import os \n",
      "import pandas as pd\n",
      "import scipy as scipy\n",
      "import scipy.io as sio\n",
      "from scipy.stats.stats import pearsonr\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Get Stimulus Information.\n",
      "Write to text file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blocks = ['A','B','C','D']\n",
      "runs = 4\n",
      "f = open('/gablab/p/eegfmri/analysis/iaps/all_labels.txt', 'w')\n",
      "for r in range(runs):\n",
      "    path_csv = '/mindhive/xnat/data/eegfmri/IAPS_realtime/listfiles'\n",
      "    path_h = os.path.join(path_csv, 'encodeBlock%s.csv' %(blocks[r]))\n",
      "    df = pd.read_csv(path_h)\n",
      "    valmn = df.valmn \n",
      "    aromn = df.aromn\n",
      "    eegcode = df.eegCode\n",
      "    binary_labels = []\n",
      "    for i in range(len(eegcode)):\n",
      "        valmn[i] = int(round(valmn[i]))\n",
      "        aromn[i] = int(round(aromn[i]))\n",
      "        if eegcode[i] >= 121:\n",
      "            binary_labels.append(1)\n",
      "        if eegcode[i] < 121:\n",
      "            binary_labels.append(-1)\n",
      "    unique = sorted(list(set(valmn)))\n",
      "    print 'Unique values in VALMN', unique\n",
      "    unique = sorted(list(set(aromn)))\n",
      "    print 'Unique values in AROMN', unique\n",
      "    corr = [scipy.stats.pearsonr(valmn, aromn)]\n",
      "    print 'Correlation between Valence and Arousal', corr\n",
      "    corr = [scipy.stats.pearsonr(valmn, binary_labels)]\n",
      "    print 'Correlation between Valence and Negative/Neutral Classification', corr\n",
      "    corr = [scipy.stats.pearsonr(aromn, binary_labels)]\n",
      "    print 'Correlation between Arousal and Negative/Neutral Classification', corr\n",
      "    print '__________________________________________________________________________________________________________'\n",
      "    print '                                                                                                          '\n",
      "    for i in range(len(eegcode)):\n",
      "        f.write(\"%s  %s  %s  %s\" %(eegcode[i], valmn[i], aromn[i], binary_labels[i]))\n",
      "        f.write('\\n')\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Unique values in VALMN [2.0, 3.0, 4.0, 5.0, 6.0]\n",
        "Unique values in AROMN [2.0, 3.0, 4.0, 5.0, 6.0, 7.0]\n",
        "Correlation between Valence and Arousal [(-0.82868708197996344, 3.0107569745223372e-16)]\n",
        "Correlation between Valence and Negative/Neutral Classification [(0.87783196660875673, 3.3933453195896632e-20)]\n",
        "Correlation between Arousal and Negative/Neutral Classification [(-0.91246391231807933, 3.5182419739934265e-24)]\n",
        "__________________________________________________________________________________________________________\n",
        "                                                                                                          \n",
        "Unique values in VALMN [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
        "Unique values in AROMN [2.0, 3.0, 4.0, 5.0, 6.0, 7.0]\n",
        "Correlation between Valence and Arousal [(-0.78620780370823584, 9.8682899188899728e-14)]\n",
        "Correlation between Valence and Negative/Neutral Classification [(0.88733494520489542, 3.7139901854993388e-21)]\n",
        "Correlation between Arousal and Negative/Neutral Classification [(-0.86690022851828141, 3.480782327813316e-19)]\n",
        "__________________________________________________________________________________________________________\n",
        "                                                                                                          \n",
        "Unique values in VALMN [2.0, 3.0, 4.0, 5.0, 6.0]\n",
        "Unique values in AROMN [2.0, 3.0, 4.0, 5.0, 6.0, 7.0]\n",
        "Correlation between Valence and Arousal [(-0.79763133237305373, 2.3821945739709809e-14)]\n",
        "Correlation between Valence and Negative/Neutral Classification [(0.86990379357889969, 1.8750735543455348e-19)]\n",
        "Correlation between Arousal and Negative/Neutral Classification [(-0.92502437972887241, 4.7024154546710388e-26)]\n",
        "__________________________________________________________________________________________________________\n",
        "                                                                                                          \n",
        "Unique values in VALMN"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
        "Unique values in AROMN [2.0, 3.0, 4.0, 5.0, 6.0, 7.0]\n",
        "Correlation between Valence and Arousal [(-0.85126255853554877, 6.955724476631113e-18)]\n",
        "Correlation between Valence and Negative/Neutral Classification [(0.88041312616706979, 1.8956514992546721e-20)]\n",
        "Correlation between Arousal and Negative/Neutral Classification [(-0.90575945770230892, 2.7204475631315682e-23)]\n",
        "__________________________________________________________________________________________________________\n",
        "                                                                                                          \n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Prepare labels, concatenate runs, setup complete dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file create_dataset.py\n",
      "\n",
      "def create_dataset(subject_id):\n",
      "    import numpy as np\n",
      "    import os \n",
      "    from nilearn import datasets\n",
      "    from nilearn.datasets import _get_dataset_dir\n",
      "    from nilearn.datasets import _get_dataset\n",
      "    from sklearn.datasets.base import Bunch\n",
      "    import pylab as pl\n",
      "    import nibabel as nb\n",
      "    \n",
      "    from remove import remove_range, remove\n",
      "\n",
      "    dataset_name = 'machine_learning'\n",
      "    runs = 4\n",
      "    img_data = np.zeros((64,64,33,1))\n",
      "    lab_data = []\n",
      "    session_data = []\n",
      "    print img_data.shape\n",
      "\n",
      "    for r in range(runs):\n",
      "        print 'RUN', r\n",
      "        rv = None\n",
      "        path = '/gablab/p/eegfmri/analysis/eeg/elists'\n",
      "        path_all_codes = '/gablab/p/eegfmri/analysis/iaps/all_labels.txt'\n",
      "        path_names2 = os.path.join(path, 'elist_IAPS_%s_%s_raw.txt' %(subject_id, r+1))\n",
      "        # ecode = np.genfromtxt(path_names, dtype=float)[:,2]\n",
      "        eegcodes = np.genfromtxt(path_all_codes, dtype=int) [:, 0]\n",
      "        attributes = np.genfromtxt(path_all_codes, dtype=float) [:, 1:4]\n",
      "        binary = attributes[:, 2]\n",
      "        run_code = np.genfromtxt(path_names2, dtype=str) [:,3]\n",
      "        clock = np.genfromtxt(path_names2, dtype=str) [:,4] \n",
      "        cl = []\n",
      "        tp = []\n",
      "        for i in range(len(clock)):\n",
      "            if run_code[i] == 'R128':\n",
      "                timepoint = clock[i].lstrip('0123456789')  \n",
      "                tp.append(timepoint)            \n",
      "            if len(tp) > 0:\n",
      "                clock[i] = clock[i].lstrip('0123456789')\n",
      "                if clock[i] == tp[0]:\n",
      "                    cl.append([i])\n",
      "                    if run_code[i] != 'R128':\n",
      "                        print i, run_code[i] \n",
      "                if clock[i] != tp[0] and run_code[i] == 'R128':\n",
      "                    print 'TR at index', i, 'to remove.'\n",
      "                    run_code[i] = 'remove'\n",
      "        print 'Numbers of TR identical timepoints', len(cl)\n",
      "        tr = []\n",
      "        for idx,i in enumerate(run_code):\n",
      "            if i == 'R128':\n",
      "                tr.append([idx])\n",
      "        print 'Number of TR counted from elist code', len(tr)\n",
      "        rv = remove(run_code, 'R')\n",
      "        rv = remove(rv, 'remove')\n",
      "        rv = remove(rv, 'boundary')\n",
      "        rv = remove(rv, 'SyncOn')\n",
      "        rv = remove(rv, 'Start')\n",
      "        rv = remove(rv, 'Userdefined')\n",
      "        rv = remove(rv, 'LowCorrelation')\n",
      "        rv = remove(rv, 'TSTART')\n",
      "        rv = remove(rv, 'TPEAK')\n",
      "        rv = remove(rv, 'TEND')\n",
      "        for i in range(len(rv)):\n",
      "            if rv[i] == 'R128':\n",
      "                rv[i] = '-99'\n",
      "            rv[i] = rv[i].lstrip('S')\n",
      "            rv[i] = int(rv[i])\n",
      "        rv = remove_range(rv, 240)\n",
      "        for idx, i in enumerate(rv):\n",
      "            for idx2, i2 in enumerate(eegcodes):\n",
      "                if i == i2: # and i!= 128:\n",
      "                    # print 'rv[idx]', rv[idx], 'aromn[idx2]', aromn[idx2]\n",
      "                    rv[idx] = binary[idx2]            \n",
      "                    # rv[idx] = int(aromn[idx2])\n",
      "        for idx, i in enumerate(rv):\n",
      "            if i != -99:\n",
      "                rv[idx-1] = i\n",
      "                rv[idx] = 0\n",
      "        # remove last code from run 1, as last TR was not recorded\n",
      "        if r == 0:\n",
      "            rv[142] = 0\n",
      "        rv = remove(rv, 0)\n",
      "        for idx, i in enumerate(rv):\n",
      "            if i == -99:\n",
      "                rv[idx] = 0\n",
      "        unique = sorted(list(set(rv)))\n",
      "        print 'Unique values in RV', unique        \n",
      "        t = open('/gablab/p/eegfmri/analysis/iaps/pilot%s/machine_learning/neg-neutr_attributes_run%s.txt' %(subject_id, r), 'w')\n",
      "        for i in range(len(rv)):\n",
      "            t.write(\"%s, %s\" %(rv[i], r))\n",
      "            t.write('\\n')  \n",
      "        t.close()\n",
      "        print 'Labels Length:', len(rv)\n",
      "        file_name = ['neg-neutr_attributes_run%s.txt' %(r), 'pilot%s_r0%s_bandpassed.nii.gz' %(subject_id, r)]\n",
      "        fil = _get_dataset(dataset_name, file_name, data_dir='/gablab/p/eegfmri/analysis/iaps/pilot%s' %(subject_id), folder=None)\n",
      "        ds_i = Bunch(func=fil[1], conditions_target=fil[0])\n",
      "        labels_i = np.loadtxt(ds_i.conditions_target, dtype=np.str)\n",
      "        bold_i = nb.load(ds_i.func)\n",
      "        fmri_data_i = np.copy(bold_i.get_data())\n",
      "        print 'fMRI data', fmri_data_i.shape\n",
      "        affine = bold_i.get_affine()\n",
      "        mean_img_i = np.mean(fmri_data_i, axis=3)\n",
      "        session_data = np.append(session_data, labels_i[:,1])\n",
      "        lab_data = np.append(lab_data, labels_i[:,0])\n",
      "        img_data = np.concatenate((img_data, fmri_data_i), axis=3)\n",
      "        print '__________________________________________________________________________________________________________'\n",
      "        if r == 3:\n",
      "            img_data = img_data[...,1:]\n",
      "            print 'fMRI image', img_data.shape\n",
      "            print 'Label Vector Length:', len(lab_data), 'Session Vector Length:', len(session_data)\n",
      "            ni_img = nb.Nifti1Image(img_data, affine=None, header=None)\n",
      "            nb.save(ni_img, '/gablab/p/eegfmri/analysis/iaps/pilot%s/machine_learning/all_runs.nii' %(subject_id))\n",
      "            f = open('/gablab/p/eegfmri/analysis/iaps/pilot%s/machine_learning/neg-neutr_attributes_all_runs.txt' %(subject_id), 'w')\n",
      "            for i in range(len(lab_data)):\n",
      "                f.write(\"%s %s\" %(lab_data[i], session_data[i]))\n",
      "                f.write('\\n')  \n",
      "            f.close()\n",
      "            # set up concatenated dataset in nilearn format\n",
      "            file_names = ['neg-neutr_attributes_all_runs.txt', 'all_runs.nii']\n",
      "            files = _get_dataset(dataset_name, file_names, data_dir='/gablab/p/eegfmri/analysis/iaps/pilot%s' %(subject_id), folder=None)\n",
      "            ds = Bunch(func=files[1], conditions_target=files[0])\n",
      "            print ds.keys(), ds\n",
      "            labels = np.loadtxt(ds.conditions_target, dtype=np.str)\n",
      "            bold = nb.load(ds.func)\n",
      "            fmri_data = np.copy(bold.get_data())\n",
      "            print fmri_data.shape\n",
      "            affine = bold_i.get_affine() # just choose one\n",
      "            # Compute the mean EPI: we do the mean along the axis 3, which is time\n",
      "            mean_img = np.mean(fmri_data, axis=3)\n",
      "    return (ds, labels, bold, fmri_data, affine, mean_img)\n",
      "\n",
      "# ds, labels, bold, fmri_data, affine, mean_img = create_dataset('009')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing create_dataset.py\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file get_subjectinfo.py\n",
      "\n",
      "# Get subjectinfo for first_level_ev\n",
      "\n",
      "def get_subjectinfo(subject_id):\n",
      "    runs = 4\n",
      "    for r in range(runs):            \n",
      "        path = '/gablab/p/eegfmri/analysis/eeg/elists'\n",
      "        path_names = os.path.join(path, 'elist_IAPS_%s_%s_raw.txt' %(subject_id, r+1))\n",
      "        if subject_id == '005' and r == 1:\n",
      "            path_names = os.path.join(path, 'elist_IAPS_%s_%s_2_raw.txt' %(subject_id, r+1))\n",
      "        if subject_id == '009':\n",
      "            path_names = os.path.join(path, 'elist_IAPS_%s_%s.txt' %(subject_id, r+1))            \n",
      "        run_code = np.genfromtxt(path_names, dtype=str) [:,3]\n",
      "        unique = sorted(list(set(run_code)))\n",
      "        clock = np.genfromtxt(path_names, dtype=str) [:,4] \n",
      "        f = open('/gablab/p/eegfmri/analysis/iaps/pilot%s/cond_neg_run%s.txt' %(subject_id, r), 'w')\n",
      "        for idx2, i2 in enumerate(run_code):\n",
      "            if i2.startswith('S') and i2 != 'SyncOn' and i2 != 'Start':\n",
      "                i2 = int(i2.lstrip('S'))\n",
      "                if i2 < 121:\n",
      "                    f.write(\"%s, 2, 1\" %(clock[idx2]))\n",
      "                    f.write('\\n') \n",
      "        f.close()\n",
      "        t = open('/gablab/p/eegfmri/analysis/iaps/pilot%s/cond_neut_run%s.txt' %(subject_id, r), 'w')\n",
      "        for idx2, i2 in enumerate(run_code):\n",
      "            if i2.startswith('S') and i2 != 'SyncOn' and i2 != 'Start':\n",
      "                i2 = int(i2.lstrip('S'))\n",
      "                if i2 >= 121:\n",
      "                    t.write(\"%s, 2, 1\" %(clock[idx2]))\n",
      "                    t.write('\\n')\n",
      "        t.close()\n",
      "        \n",
      "a = get_subjectinfo('004')\n",
      "b = get_subjectinfo('005')        \n",
      "c = get_subjectinfo('006')        \n",
      "d = get_subjectinfo('007')        \n",
      "e = get_subjectinfo('008')        \n",
      "f = get_subjectinfo('009')        \n",
      "g = get_subjectinfo('011')        \n",
      "h = get_subjectinfo('012')        \n",
      "i = get_subjectinfo('013')        \n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Apply Amygdala Mask to Dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      " 31  54        49     1631.7  Right-Amygdala                   854.8610    30.4415   780.8995   908.1414   127.2419 \n",
      " 15  18        49     1631.7  Left-Amygdala                    807.0057    31.3772   733.2222   865.2081   131.9859 "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file apply_mask.py\n",
      "\n",
      "command_r = 'fslmaths /gablab/p/eegfmri/analysis/iaps/pilot009/segstats/aparc+aseg-in-func.nii -uthr 55 -thr 53 /gablab/p/eegfmri/analysis/iaps/pilot009/segstats/right_amygdala_mask.nii' \n",
      "a = os.system(command_r)\n",
      "command_l = 'fslmaths /gablab/p/eegfmri/analysis/iaps/pilot009/segstats/aparc+aseg-in-func.nii -uthr 19 -thr 17 /gablab/p/eegfmri/analysis/iaps/pilot009/segstats/left_amygdala_mask.nii' \n",
      "a = os.system(command_l)\n",
      "\n",
      "# try mri_binarize\n",
      "\n",
      "def apply_mask(subject_id, bold):\n",
      "    import nibabel as nb\n",
      "    import pylab as pl\n",
      "    from nilearn.masking import _load_mask_img, compute_epi_mask, apply_mask, _unmask_nd, _apply_mask_fmri\n",
      "    from nilearn import _utils, resampling\n",
      "    from nilearn._utils.ndimage import largest_connected_component\n",
      "    from nilearn._utils.cache_mixin import cache\n",
      "    ra = '/gablab/p/eegfmri/analysis/iaps/pilot%s/segstats/right_amygdala_mask.nii.gz' %(subject_id)\n",
      "    ra = nb.load(ra)\n",
      "    la = '/gablab/p/eegfmri/analysis/iaps/pilot%s/segstats/left_amygdala_mask.nii.gz' %(subject_id)\n",
      "    la = nb.load(la)\n",
      "    # f = _apply_mask_fmri(bold_1, b) and NiftiMasker do not work -- doing this manually:\n",
      "    rd = _utils.as_ndarray(ra.get_data(),dtype=np.bool)\n",
      "    ld = _utils.as_ndarray(la.get_data(),dtype=np.bool)\n",
      "    rl = rd+ld\n",
      "    mask_img = ra # or la \n",
      "    mask_data = rl\n",
      "    mask_affine = mask_img.get_affine() # gets only affine of ra\n",
      "    print 'Mask [ra] affine'\n",
      "    print mask_affine\n",
      "    print 'fMRI affine'\n",
      "    print affine\n",
      "    data = bold.get_data()\n",
      "    series = _utils.as_ndarray(data, dtype=dtype, order=\"C\", copy=True)\n",
      "    X = series[mask_data].T\n",
      "    # mask_img = mask_data.get_data()\n",
      "    print 'Masked Data', X.shape\n",
      "    u = _unmask_nd(X, mask_data)\n",
      "    mean_img_u = np.mean(u, axis=3, dtype=float)\n",
      "    figure(figsize=(20,5), dpi=80)\n",
      "    pl.figure\n",
      "    pl.title('Mask Amygdala')\n",
      "    plt.imshow(np.rot90(mean_img_u[:, :, 5]), interpolation='nearest')\n",
      "    return X\n",
      "\n",
      "# apply_mask('009', bold)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting apply_mask.py\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Searchlight Computation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nilearn.io import NiftiMasker\n",
      "from nibabel import Nifti1Image\n",
      "\n",
      "# Nifti Mask\n",
      "nifti_masker = NiftiMasker(mask=None, sessions=session, memory=\"nilearn_cache\", memory_level=1)\n",
      "mask_img = Nifti1Image(fmri_data, affine)\n",
      "mask_data_all = nifti_masker.fit_transform(img)\n",
      "\n",
      "# Anatomical Mask Manually\n",
      "\n",
      "from nilearn.masking import compute_epi_mask, apply_mask, _unmask_nd\n",
      "bin_mask_img = compute_epi_mask(bold)\n",
      "bin_mask_data= bin_mask_img.get_data().astype(bool)\n",
      "print bin_mask_data.shape # equivalent to mask_data_all\n",
      "\n",
      "masked_data = apply_mask(bold, bin_mask_img)\n",
      "print masked_data.shape\n",
      "\n",
      "figure(figsize=(20,5), dpi=80)\n",
      "pl.figure\n",
      "pl.axis('off')\n",
      "pl.title('Mask')\n",
      "pl.imshow(np.rot90(bin_mask_data[:, :, 15]), interpolation='nearest')\n",
      "\n",
      "'''\n",
      "# Restrict to specific conditions (for now get rid of 0, not advisable for later)\n",
      "y = labels[:,0]\n",
      "session = labels[:,1]\n",
      "condition_mask = np.logical_or(y == '-1.0,', y == '1.0,')\n",
      "fmri_img = nb.Nifti1Image(bold.get_data()[..., condition_mask], affine)\n",
      "y, session = y[condition_mask], session[condition_mask]\n",
      "conditions = labels[condition_mask]\n",
      "\n",
      "n_jobs = 1\n",
      "\n",
      "from sklearn.metrics import precision_score\n",
      "score_func = precision_score\n",
      "from sklearn.cross_validation import KFold\n",
      "print y.size\n",
      "cv = KFold(y.size, k=4)\n",
      "\n",
      "import nilearn.decoding\n",
      "# The radius is the one of the Searchlight sphere that will scan the volume\n",
      "searchlight = nilearn.decoding.SearchLight(mask_img, process_mask_img=process_mask_img, radius=5.6, n_jobs=n_jobs, score_func=score_func, verbose=1, cv=cv)\n",
      "searchlight.fit(fmri_img, y)\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(64, 64, 33)\n",
        "(574, 45065)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 152,
       "text": [
        "\"\\n# Restrict to specific conditions (for now get rid of 0, not advisable for later)\\ny = labels[:,0]\\nsession = labels[:,1]\\ncondition_mask = np.logical_or(y == '-1.0,', y == '1.0,')\\nfmri_img = nb.Nifti1Image(bold.get_data()[..., condition_mask], affine)\\ny, session = y[condition_mask], session[condition_mask]\\nconditions = labels[condition_mask]\\n\\nn_jobs = 1\\n\\nfrom sklearn.metrics import precision_score\\nscore_func = precision_score\\nfrom sklearn.cross_validation import KFold\\nprint y.size\\ncv = KFold(y.size, k=4)\\n\\nimport nilearn.decoding\\n# The radius is the one of the Searchlight sphere that will scan the volume\\nsearchlight = nilearn.decoding.SearchLight(mask_img, process_mask_img=process_mask_img, radius=5.6, n_jobs=n_jobs, score_func=score_func, verbose=1, cv=cv)\\nsearchlight.fit(fmri_img, y)\\n\""
       ]
      },
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAATQAAAFACAYAAAAyMoBIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEPQgBiCBsT4H+zAS9V2DJTsAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x20f3d450>"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Standardization & Classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm, preprocessing\n",
      "from sklearn.svm import LinearSVC\n",
      "import pylab as pl\n",
      "from sklearn.preprocessing import _mean_and_std, StandardScaler\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "from sklearn.metrics import auc_score\n",
      "from sklearn.metrics import auc\n",
      "\n",
      "# Restrict to specific conditions (for now get rid of 0, not advisable for later)\n",
      "y = labels[:,0]\n",
      "session = labels[:,1]\n",
      "condition_mask = np.logical_or(y == '-1', y == '1')\n",
      "fmri_img = nb.Nifti1Image(bold.get_data()[..., condition_mask], affine)\n",
      "y, session = y[condition_mask], session[condition_mask]\n",
      "conditions = labels[condition_mask]\n",
      "\n",
      "#### Searchlight \n",
      "\n",
      "\n",
      "\n",
      "#####\n",
      "Xs = preprocessing.scale(X) \n",
      "\n",
      "# use pipeline instead\n",
      "#scaling_svm = Pipeline([(\"scaler\", Scaler()), (\"svm\", SVC(C=1000))])\n",
      "\n",
      "#scaler = StandardScaler()\n",
      "#Xs = scaler.fit(X)\n",
      "#Xs = scaler.transform(X) \n",
      "\n",
      "X = Xs\n",
      "clf = svm.SVC(kernel='linear', probability=True)\n",
      "y_pred = clf.fit(X, y).predict(X)\n",
      "svc = clf.support_vectors_\n",
      "\n",
      "print svc.shape\n",
      "print X.shape\n",
      "u = _unmask_nd(svc, mask_data) # unmask unseen data?\n",
      "mean_img_u = np.mean(u, axis=3, dtype=float)\n",
      "act_u = np.ma.masked_array(mean_img_u, mean_img_u == 0)\n",
      "figure(figsize=(20,5), dpi=80)\n",
      "pl.figure\n",
      "pl.subplot(1, 2, 1)\n",
      "pl.imshow(np.rot90(mean_img[:, :, 5]), cmap=pl.cm.gray, interpolation='nearest')\n",
      "plt.imshow(np.rot90(act_u[:, :, 5]),cmap=pl.cm.hot, interpolation='nearest')\n",
      "pl.title('Unmask SVC Vectors')\n",
      "\n",
      "# area = auc_score(y, y_pred)\n",
      "# print area\n",
      "\n",
      "# from sklearn.metrics import average_precision_score\n",
      "# avp = average_precision_score(y, y_pred)\n",
      "# print avp\n",
      "\n",
      "from sklearn.metrics import classification_report\n",
      "target_names = ['-1','0', '1']\n",
      "# print (classification_report(y, y_pred, target_names=target_names))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'labels' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-107-8d6414457751>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Restrict to specific conditions (for now get rid of 0, not advisable for later)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mcondition_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'-1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}