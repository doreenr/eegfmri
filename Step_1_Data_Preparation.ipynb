{
 "metadata": {
  "name": "Step_1_Data_Preparation"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Welcome to pylab, a matplotlib-based Python environment [backend: module://IPython.kernel.zmq.pylab.backend_inline].\n",
        "For more information, type 'help(pylab)'.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file remove.py\n",
      "\n",
      "def remove(lister, val):\n",
      "   return [value for value in lister if value != val]\n",
      "\n",
      "def remove_range(lister, val):\n",
      "   return [value for value in lister if value < val]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing remove.py\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pylab as plt\n",
      "import os \n",
      "import pandas as pd\n",
      "import scipy as scipy\n",
      "import scipy.io as sio\n",
      "from scipy.stats.stats import pearsonr\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Get Stimulus Information.\n",
      "Write to text file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blocks = ['A','B','C','D']\n",
      "runs = 4\n",
      "f = open('/gablab/p/eegfmri/analysis/iaps/all_labels.txt', 'w')\n",
      "for r in range(runs):\n",
      "    path_csv = '/mindhive/xnat/data/eegfmri/IAPS_realtime/listfiles'\n",
      "    path_h = os.path.join(path_csv, 'encodeBlock%s.csv' %(blocks[r]))\n",
      "    df = pd.read_csv(path_h)\n",
      "    valmn = df.valmn \n",
      "    aromn = df.aromn\n",
      "    eegcode = df.eegCode\n",
      "    binary_labels = []\n",
      "    for i in range(len(eegcode)):\n",
      "        valmn[i] = int(round(valmn[i]))\n",
      "        aromn[i] = int(round(aromn[i]))\n",
      "        if eegcode[i] >= 121:\n",
      "            binary_labels.append(1)\n",
      "        if eegcode[i] < 121:\n",
      "            binary_labels.append(-1)\n",
      "    unique = sorted(list(set(valmn)))\n",
      "    print 'Unique values in VALMN', unique\n",
      "    unique = sorted(list(set(aromn)))\n",
      "    print 'Unique values in AROMN', unique\n",
      "    corr = [scipy.stats.pearsonr(valmn, aromn)]\n",
      "    print 'Correlation between Valence and Arousal', corr\n",
      "    corr = [scipy.stats.pearsonr(valmn, binary_labels)]\n",
      "    print 'Correlation between Valence and Negative/Neutral Classification', corr\n",
      "    corr = [scipy.stats.pearsonr(aromn, binary_labels)]\n",
      "    print 'Correlation between Arousal and Negative/Neutral Classification', corr\n",
      "    print '__________________________________________________________________________________________________________'\n",
      "    print '                                                                                                          '\n",
      "    for i in range(len(eegcode)):\n",
      "        f.write(\"%s  %s  %s  %s\" %(eegcode[i], valmn[i], aromn[i], binary_labels[i]))\n",
      "        f.write('\\n')\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Unique values in VALMN [2.0, 3.0, 4.0, 5.0, 6.0]\n",
        "Unique values in AROMN [2.0, 3.0, 4.0, 5.0, 6.0, 7.0]\n",
        "Correlation between Valence and Arousal [(-0.82868708197996344, 3.0107569745223372e-16)]\n",
        "Correlation between Valence and Negative/Neutral Classification [(0.87783196660875673, 3.3933453195896632e-20)]\n",
        "Correlation between Arousal and Negative/Neutral Classification [(-0.91246391231807933, 3.5182419739934265e-24)]\n",
        "__________________________________________________________________________________________________________\n",
        "                                                                                                          \n",
        "Unique values in VALMN [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
        "Unique values in AROMN [2.0, 3.0, 4.0, 5.0, 6.0, 7.0]\n",
        "Correlation between Valence and Arousal [(-0.78620780370823584, 9.8682899188899728e-14)]\n",
        "Correlation between Valence and Negative/Neutral Classification [(0.88733494520489542, 3.7139901854993388e-21)]\n",
        "Correlation between Arousal and Negative/Neutral Classification [(-0.86690022851828141, 3.480782327813316e-19)]\n",
        "__________________________________________________________________________________________________________\n",
        "                                                                                                          \n",
        "Unique values in VALMN [2.0, 3.0, 4.0, 5.0, 6.0]\n",
        "Unique values in AROMN [2.0, 3.0, 4.0, 5.0, 6.0, 7.0]\n",
        "Correlation between Valence and Arousal [(-0.79763133237305373, 2.3821945739709809e-14)]\n",
        "Correlation between Valence and Negative/Neutral Classification [(0.86990379357889969, 1.8750735543455348e-19)]\n",
        "Correlation between Arousal and Negative/Neutral Classification [(-0.92502437972887241, 4.7024154546710388e-26)]\n",
        "__________________________________________________________________________________________________________\n",
        "                                                                                                          \n",
        "Unique values in VALMN"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
        "Unique values in AROMN [2.0, 3.0, 4.0, 5.0, 6.0, 7.0]\n",
        "Correlation between Valence and Arousal [(-0.85126255853554877, 6.955724476631113e-18)]\n",
        "Correlation between Valence and Negative/Neutral Classification [(0.88041312616706979, 1.8956514992546721e-20)]\n",
        "Correlation between Arousal and Negative/Neutral Classification [(-0.90575945770230892, 2.7204475631315682e-23)]\n",
        "__________________________________________________________________________________________________________\n",
        "                                                                                                          \n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Prepare labels, concatenate runs, setup complete dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file create_dataset.py\n",
      "\n",
      "def create_dataset(subject_id):\n",
      "    import numpy as np\n",
      "    import os \n",
      "    from nilearn import datasets\n",
      "    from nilearn.datasets import _get_dataset_dir\n",
      "    from nilearn.datasets import _get_dataset\n",
      "    from sklearn.datasets.base import Bunch\n",
      "    import pylab as pl\n",
      "    import nibabel as nb\n",
      "    \n",
      "    from remove import remove_range, remove\n",
      "\n",
      "    dataset_name = 'machine_learning'\n",
      "    runs = 4\n",
      "    img_data = np.zeros((64,64,33,1))\n",
      "    lab_data = []\n",
      "    session_data = []\n",
      "    print img_data.shape\n",
      "\n",
      "    for r in range(runs):\n",
      "        print 'RUN', r\n",
      "        rv = None\n",
      "        path = '/gablab/p/eegfmri/analysis/eeg/elists'\n",
      "        path_all_codes = '/gablab/p/eegfmri/analysis/iaps/all_labels.txt'\n",
      "        path_names2 = os.path.join(path, 'IAPS_%s_%s_raw.txt' %(subject_id, r+1))\n",
      "        # ecode = np.genfromtxt(path_names, dtype=float)[:,2]\n",
      "        eegcodes = np.genfromtxt(path_all_codes, dtype=int) [:, 0]\n",
      "        attributes = np.genfromtxt(path_all_codes, dtype=float) [:, 1:4]\n",
      "        binary = attributes[:, 2]\n",
      "        run_code = np.genfromtxt(path_names2, dtype=str) [:,3]\n",
      "        clock = np.genfromtxt(path_names2, dtype=str) [:,4] \n",
      "        cl = []\n",
      "        tp = []\n",
      "        for i in range(len(clock)):\n",
      "            if run_code[i] == 'R128':\n",
      "                timepoint = clock[i].lstrip('0123456789')  \n",
      "                tp.append(timepoint)            \n",
      "            if len(tp) > 0:\n",
      "                clock[i] = clock[i].lstrip('0123456789')\n",
      "                if clock[i] == tp[0]:\n",
      "                    cl.append([i])\n",
      "                    if run_code[i] != 'R128':\n",
      "                        print i, run_code[i] \n",
      "                if clock[i] != tp[0] and run_code[i] == 'R128':\n",
      "                    print 'TR at index', i, 'to remove.'\n",
      "                    run_code[i] = 'remove'\n",
      "        print 'Numbers of TR identical timepoints', len(cl)\n",
      "        tr = []\n",
      "        for idx,i in enumerate(run_code):\n",
      "            if i == 'R128':\n",
      "                tr.append([idx])\n",
      "        print 'Number of TR counted from elist code', len(tr)\n",
      "        rv = remove(run_code, 'R')\n",
      "        rv = remove(rv, 'remove')\n",
      "        rv = remove(rv, 'boundary')\n",
      "        rv = remove(rv, 'SyncOn')\n",
      "        rv = remove(rv, 'Start')\n",
      "        rv = remove(rv, 'Userdefined')\n",
      "        rv = remove(rv, 'LowCorrelation')\n",
      "        rv = remove(rv, 'TSTART')\n",
      "        rv = remove(rv, 'TPEAK')\n",
      "        rv = remove(rv, 'TEND')\n",
      "        for i in range(len(rv)):\n",
      "            if rv[i] == 'R128':\n",
      "                rv[i] = '-99'\n",
      "            rv[i] = rv[i].lstrip('S')\n",
      "            rv[i] = int(rv[i])\n",
      "        rv = remove_range(rv, 240)\n",
      "        for idx, i in enumerate(rv):\n",
      "            for idx2, i2 in enumerate(eegcodes):\n",
      "                if i == i2: # and i!= 128:\n",
      "                    # print 'rv[idx]', rv[idx], 'aromn[idx2]', aromn[idx2]\n",
      "                    rv[idx] = binary[idx2]            \n",
      "                    # rv[idx] = int(aromn[idx2])\n",
      "        for idx, i in enumerate(rv):\n",
      "            if i != -99:\n",
      "                rv[idx-1] = i\n",
      "                rv[idx] = 0\n",
      "        # remove last code from run 1, as last TR was not recorded\n",
      "        if r == 0:\n",
      "            rv[142] = 0\n",
      "        rv = remove(rv, 0)\n",
      "        for idx, i in enumerate(rv):\n",
      "            if i == -99:\n",
      "                rv[idx] = 0\n",
      "        unique = sorted(list(set(rv)))\n",
      "        print 'Unique values in RV', unique        \n",
      "        t = open('/gablab/p/eegfmri/analysis/iaps/pilot%s/machine_learning/neg-neutr_attributes_run%s.txt' %(subject_id, r), 'w')\n",
      "        for i in range(len(rv)):\n",
      "            t.write(\"%s, %s\" %(rv[i], r))\n",
      "            t.write('\\n')  \n",
      "        t.close()\n",
      "        print 'Labels Length:', len(rv)\n",
      "        file_name = ['neg-neutr_attributes_run%s.txt' %(r), 'pilot%s_r0%s_bandpassed.nii.gz' %(subject_id, r)]\n",
      "        fil = _get_dataset(dataset_name, file_name, data_dir='/gablab/p/eegfmri/analysis/iaps/pilot%s' %(subject_id), folder=None)\n",
      "        ds_i = Bunch(func=fil[1], conditions_target=fil[0])\n",
      "        labels_i = np.loadtxt(ds_i.conditions_target, dtype=np.str)\n",
      "        bold_i = nb.load(ds_i.func)\n",
      "        fmri_data_i = np.copy(bold_i.get_data())\n",
      "        print 'fMRI data', fmri_data_i.shape\n",
      "        affine = bold_i.get_affine()\n",
      "        mean_img_i = np.mean(fmri_data_i, axis=3)\n",
      "        session_data = np.append(session_data, labels_i[:,1])\n",
      "        lab_data = np.append(lab_data, labels_i[:,0])\n",
      "        img_data = np.concatenate((img_data, fmri_data_i), axis=3)\n",
      "        print '__________________________________________________________________________________________________________'\n",
      "        if r == 3:\n",
      "            img_data = img_data[...,1:]\n",
      "            print 'fMRI image', img_data.shape\n",
      "            print 'Label Vector Length:', len(lab_data), 'Session Vector Length:', len(session_data)\n",
      "            ni_img = nb.Nifti1Image(img_data, affine=None, header=None)\n",
      "            nb.save(ni_img, '/gablab/p/eegfmri/analysis/iaps/pilot%s/machine_learning/all_runs.nii' %(subject_id))\n",
      "            f = open('/gablab/p/eegfmri/analysis/iaps/pilot%s/machine_learning/neg-neutr_attributes_all_runs.txt' %(subject_id), 'w')\n",
      "            for i in range(len(lab_data)):\n",
      "                f.write(\"%s %s\" %(lab_data[i], session_data[i]))\n",
      "                f.write('\\n')  \n",
      "            f.close()\n",
      "            # set up concatenated dataset in nilearn format\n",
      "            file_names = ['neg-neutr_attributes_all_runs.txt', 'all_runs.nii']\n",
      "            files = _get_dataset(dataset_name, file_names, data_dir='/gablab/p/eegfmri/analysis/iaps/pilot%s' %(subject_id), folder=None)\n",
      "            ds = Bunch(func=files[1], conditions_target=files[0])\n",
      "            print ds.keys(), ds\n",
      "            labels = np.loadtxt(ds.conditions_target, dtype=np.str)\n",
      "            bold = nb.load(ds.func)\n",
      "            fmri_data = np.copy(bold.get_data())\n",
      "            print fmri_data.shape\n",
      "            affine = bold_i.get_affine() # just choose one\n",
      "            # Compute the mean EPI: we do the mean along the axis 3, which is time\n",
      "            mean_img = np.mean(fmri_data, axis=3)\n",
      "    return (ds, labels, bold, fmri_data, affine, mean_img)\n",
      "\n",
      "# ds, labels, bold, fmri_data, affine, mean_img = create_dataset('009')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing create_dataset.py\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Apply Amygdala Mask to Dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      " 31  54        49     1631.7  Right-Amygdala                   854.8610    30.4415   780.8995   908.1414   127.2419 \n",
      " 15  18        49     1631.7  Left-Amygdala                    807.0057    31.3772   733.2222   865.2081   131.9859 "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file apply_mask.py\n",
      "\n",
      "command_r = 'fslmaths /gablab/p/eegfmri/analysis/iaps/pilot009/segstats/aparc+aseg-in-func.nii -uthr 55 -thr 53 /gablab/p/eegfmri/analysis/iaps/pilot009/segstats/right_amygdala_mask.nii' \n",
      "a = os.system(command_r)\n",
      "command_l = 'fslmaths /gablab/p/eegfmri/analysis/iaps/pilot009/segstats/aparc+aseg-in-func.nii -uthr 19 -thr 17 /gablab/p/eegfmri/analysis/iaps/pilot009/segstats/left_amygdala_mask.nii' \n",
      "a = os.system(command_l)\n",
      "\n",
      "# try mri_binarize\n",
      "\n",
      "def apply_mask(subject_id, bold):\n",
      "    import nibabel as nb\n",
      "    import pylab as pl\n",
      "    from nilearn.masking import _load_mask_img, compute_epi_mask, apply_mask, _unmask_nd, _apply_mask_fmri\n",
      "    from nilearn import _utils, resampling\n",
      "    from nilearn._utils.ndimage import largest_connected_component\n",
      "    from nilearn._utils.cache_mixin import cache\n",
      "    ra = '/gablab/p/eegfmri/analysis/iaps/pilot%s/segstats/right_amygdala_mask.nii.gz' %(subject_id)\n",
      "    ra = nb.load(ra)\n",
      "    la = '/gablab/p/eegfmri/analysis/iaps/pilot%s/segstats/left_amygdala_mask.nii.gz' %(subject_id)\n",
      "    la = nb.load(la)\n",
      "    # f = _apply_mask_fmri(bold_1, b) and NiftiMasker do not work -- doing this manually:\n",
      "    rd = _utils.as_ndarray(ra.get_data(),dtype=np.bool)\n",
      "    ld = _utils.as_ndarray(la.get_data(),dtype=np.bool)\n",
      "    rl = rd+ld\n",
      "    mask_img = ra # or la \n",
      "    mask_data = rl\n",
      "    mask_affine = mask_img.get_affine() # gets only affine of ra\n",
      "    print 'Mask [ra] affine'\n",
      "    print mask_affine\n",
      "    print 'fMRI affine'\n",
      "    print affine\n",
      "    data = bold.get_data()\n",
      "    series = _utils.as_ndarray(data, dtype=dtype, order=\"C\", copy=True)\n",
      "    X = series[mask_data].T\n",
      "    # mask_img = mask_data.get_data()\n",
      "    print 'Masked Data', X.shape\n",
      "    u = _unmask_nd(X, mask_data)\n",
      "    mean_img_u = np.mean(u, axis=3, dtype=float)\n",
      "    figure(figsize=(20,5), dpi=80)\n",
      "    pl.figure\n",
      "    pl.title('Mask Amygdala')\n",
      "    plt.imshow(np.rot90(mean_img_u[:, :, 5]), interpolation='nearest')\n",
      "    return X\n",
      "\n",
      "# apply_mask('009', bold)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting apply_mask.py\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Searchlight Computation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nilearn.io import NiftiMasker\n",
      "from nibabel import Nifti1Image\n",
      "\n",
      "# Nifti Mask\n",
      "nifti_masker = NiftiMasker(mask=None, sessions=session, memory=\"nilearn_cache\", memory_level=1)\n",
      "mask_img = Nifti1Image(fmri_data, affine)\n",
      "mask_data_all = nifti_masker.fit_transform(img)\n",
      "\n",
      "# Anatomical Mask Manually\n",
      "\n",
      "from nilearn.masking import compute_epi_mask, apply_mask, _unmask_nd\n",
      "bin_mask_img = compute_epi_mask(bold)\n",
      "bin_mask_data= bin_mask_img.get_data().astype(bool)\n",
      "print bin_mask_data.shape # equivalent to mask_data_all\n",
      "\n",
      "masked_data = apply_mask(bold, bin_mask_img)\n",
      "print masked_data.shape\n",
      "\n",
      "figure(figsize=(20,5), dpi=80)\n",
      "pl.figure\n",
      "pl.axis('off')\n",
      "pl.title('Mask')\n",
      "pl.imshow(np.rot90(bin_mask_data[:, :, 15]), interpolation='nearest')\n",
      "\n",
      "'''\n",
      "# Restrict to specific conditions (for now get rid of 0, not advisable for later)\n",
      "y = labels[:,0]\n",
      "session = labels[:,1]\n",
      "condition_mask = np.logical_or(y == '-1.0,', y == '1.0,')\n",
      "fmri_img = nb.Nifti1Image(bold.get_data()[..., condition_mask], affine)\n",
      "y, session = y[condition_mask], session[condition_mask]\n",
      "conditions = labels[condition_mask]\n",
      "\n",
      "n_jobs = 1\n",
      "\n",
      "from sklearn.metrics import precision_score\n",
      "score_func = precision_score\n",
      "from sklearn.cross_validation import KFold\n",
      "print y.size\n",
      "cv = KFold(y.size, k=4)\n",
      "\n",
      "import nilearn.decoding\n",
      "# The radius is the one of the Searchlight sphere that will scan the volume\n",
      "searchlight = nilearn.decoding.SearchLight(mask_img, process_mask_img=process_mask_img, radius=5.6, n_jobs=n_jobs, score_func=score_func, verbose=1, cv=cv)\n",
      "searchlight.fit(fmri_img, y)\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(64, 64, 33)\n",
        "(574, 45065)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 152,
       "text": [
        "\"\\n# Restrict to specific conditions (for now get rid of 0, not advisable for later)\\ny = labels[:,0]\\nsession = labels[:,1]\\ncondition_mask = np.logical_or(y == '-1.0,', y == '1.0,')\\nfmri_img = nb.Nifti1Image(bold.get_data()[..., condition_mask], affine)\\ny, session = y[condition_mask], session[condition_mask]\\nconditions = labels[condition_mask]\\n\\nn_jobs = 1\\n\\nfrom sklearn.metrics import precision_score\\nscore_func = precision_score\\nfrom sklearn.cross_validation import KFold\\nprint y.size\\ncv = KFold(y.size, k=4)\\n\\nimport nilearn.decoding\\n# The radius is the one of the Searchlight sphere that will scan the volume\\nsearchlight = nilearn.decoding.SearchLight(mask_img, process_mask_img=process_mask_img, radius=5.6, n_jobs=n_jobs, score_func=score_func, verbose=1, cv=cv)\\nsearchlight.fit(fmri_img, y)\\n\""
       ]
      },
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAATQAAAFACAYAAAAyMoBIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEPQgBiCBsT4H+zAS9V2DJTsAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x20f3d450>"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Standardization & Classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import svm, preprocessing\n",
      "from sklearn.svm import LinearSVC\n",
      "import pylab as pl\n",
      "from sklearn.preprocessing import _mean_and_std, StandardScaler\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "from sklearn.metrics import auc_score\n",
      "from sklearn.metrics import auc\n",
      "\n",
      "# Restrict to specific conditions (for now get rid of 0, not advisable for later)\n",
      "y = labels[:,0]\n",
      "session = labels[:,1]\n",
      "condition_mask = np.logical_or(y == '-1', y == '1')\n",
      "fmri_img = nb.Nifti1Image(bold.get_data()[..., condition_mask], affine)\n",
      "y, session = y[condition_mask], session[condition_mask]\n",
      "conditions = labels[condition_mask]\n",
      "\n",
      "#### Searchlight \n",
      "\n",
      "\n",
      "\n",
      "#####\n",
      "Xs = preprocessing.scale(X) \n",
      "\n",
      "# use pipeline instead\n",
      "#scaling_svm = Pipeline([(\"scaler\", Scaler()), (\"svm\", SVC(C=1000))])\n",
      "\n",
      "#scaler = StandardScaler()\n",
      "#Xs = scaler.fit(X)\n",
      "#Xs = scaler.transform(X) \n",
      "\n",
      "X = Xs\n",
      "clf = svm.SVC(kernel='linear', probability=True)\n",
      "y_pred = clf.fit(X, y).predict(X)\n",
      "svc = clf.support_vectors_\n",
      "\n",
      "print svc.shape\n",
      "print X.shape\n",
      "u = _unmask_nd(svc, mask_data) # unmask unseen data?\n",
      "mean_img_u = np.mean(u, axis=3, dtype=float)\n",
      "act_u = np.ma.masked_array(mean_img_u, mean_img_u == 0)\n",
      "figure(figsize=(20,5), dpi=80)\n",
      "pl.figure\n",
      "pl.subplot(1, 2, 1)\n",
      "pl.imshow(np.rot90(mean_img[:, :, 5]), cmap=pl.cm.gray, interpolation='nearest')\n",
      "plt.imshow(np.rot90(act_u[:, :, 5]),cmap=pl.cm.hot, interpolation='nearest')\n",
      "pl.title('Unmask SVC Vectors')\n",
      "\n",
      "# area = auc_score(y, y_pred)\n",
      "# print area\n",
      "\n",
      "# from sklearn.metrics import average_precision_score\n",
      "# avp = average_precision_score(y, y_pred)\n",
      "# print avp\n",
      "\n",
      "from sklearn.metrics import classification_report\n",
      "target_names = ['-1','0', '1']\n",
      "print (classification_report(y, y_pred, target_names=target_names))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['0,' '0,' '1.0,' '0,' '0,' '-1.0,' '0,' '-1.0,' '0,' '-1.0,' '0,' '1.0,'\n",
        " '0,' '0,' '1.0,' '0,' '1.0,' '0,' '-1.0,' '0,' '0,' '-1.0,' '0,' '0,'\n",
        " '1.0,' '0,' '-1.0,' '0,' '0,' '1.0,' '0,' '0,' '-1.0,' '0,' '0,' '-1.0,'\n",
        " '0,' '-1.0,' '0,' '1.0,' '0,' '0,' '1.0,' '0,' '-1.0,' '0,' '1.0,' '0,'\n",
        " '-1.0,' '0,' '1.0,' '0,' '0,' '-1.0,' '0,' '1.0,' '-1.0,' '0,' '-1.0,'\n",
        " '0,' '0,' '-1.0,' '0,' '1.0,' '0,' '0,' '1.0,' '0,' '1.0,' '0,' '1.0,'\n",
        " '0,' '0,' '1.0,' '0,' '0,' '-1.0,' '-1.0,' '0,' '0,' '-1.0,' '0,' '-1.0,'\n",
        " '0,' '1.0,' '0,' '1.0,' '0,' '-1.0,' '0,' '1.0,' '0,' '0,' '1.0,' '0,'\n",
        " '1.0,' '0,' '0,' '-1.0,' '0,' '0,' '0,' '1.0,' '0,' '-1.0,' '0,' '0,'\n",
        " '1.0,' '0,' '0,' '0,' '0,' '-1.0,' '0,' '1.0,' '0,' '-1.0,' '0,' '0,'\n",
        " '1.0,' '0,' '0,' '-1.0,' '0,' '0,' '-1.0,' '0,' '1.0,' '0,' '0,' '-1.0,'\n",
        " '0,' '0,' '-1.0,' '0,' '1.0,' '0,' '-1.0,' '0,' '0,' '1.0,' '1.0,' '0,'\n",
        " '0,' '1.0,' '0,' '-1.0,' '0,' '0,' '-1.0,' '0,' '-1.0,' '0,' '0,' '1.0,'\n",
        " '0,' '0,' '1.0,' '0,' '1.0,' '0,' '0,' '-1.0,' '0,' '-1.0,' '0,' '0,'\n",
        " '1.0,' '-1.0,' '0,' '0,' '1.0,' '0,' '0,' '-1.0,' '0,' '-1.0,' '0,'\n",
        " '-1.0,' '0,' '1.0,' '0,' '1.0,' '0,' '-1.0,' '0,' '0,' '1.0,' '0,' '0,'\n",
        " '-1.0,' '1.0,' '0,' '-1.0,' '0,' '1.0,' '0,' '0,' '-1.0,' '0,' '-1.0,'\n",
        " '0,' '-1.0,' '0,' '1.0,' '0,' '1.0,' '0,' '0,' '1.0,' '1.0,' '0,' '0,'\n",
        " '1.0,' '0,' '-1.0,' '0,' '0,' '-1.0,' '0,' '-1.0,' '0,' '-1.0,' '0,' '0,'\n",
        " '1.0,' '0,' '0,' '1.0,' '0,' '-1.0,' '0,' '0,' '1.0,' '1.0,' '0,' '0,'\n",
        " '1.0,' '0,' '-1.0,' '-1.0,' '0,' '0,' '1.0,' '0,' '-1.0,' '0,' '1.0,' '0,'\n",
        " '1.0,' '0,' '-1.0,' '0,' '0,' '1.0,' '0,' '0,' '-1.0,' '0,' '1.0,' '0,'\n",
        " '-1.0,' '0,' '0,' '-1.0,' '0,' '0,' '1.0,' '0,' '-1.0,' '0,' '0,' '-1.0,'\n",
        " '0,' '0,' '1.0,' '0,' '0,' '-1.0,' '0,' '1.0,' '0,' '1.0,' '0,' '0,' '0,'\n",
        " '0,' '0,' '1.0,' '0,' '0,' '-1.0,' '0,' '-1.0,' '0,' '0,' '-1.0,' '0,'\n",
        " '0,' '1.0,' '0,' '0,' '1.0,' '0,' '0,' '1.0,' '-1.0,' '0,' '0,' '-1.0,'\n",
        " '0,' '1.0,' '0,' '-1.0,' '0,' '1.0,' '0,' '0,' '-1.0,' '0,' '-1.0,' '0,'\n",
        " '-1.0,' '0,' '0,' '1.0,' '0,' '1.0,' '0,' '-1.0,' '0,' '0,' '1.0,' '0,'\n",
        " '-1.0,' '0,' '0,' '1.0,' '0,' '-1.0,' '0,' '1.0,' '0,' '0,' '-1.0,' '0,'\n",
        " '0,' '-1.0,' '0,' '0,' '-1.0,' '0,' '1.0,' '0,' '0,' '1.0,' '0,' '1.0,'\n",
        " '0,' '1.0,' '0,' '1.0,' '0,' '0,' '-1.0,' '0,' '-1.0,' '0,' '0,' '-1.0,'\n",
        " '0,' '-1.0,' '0,' '1.0,' '0,' '0,' '1.0,' '0,' '0,' '-1.0,' '0,' '1.0,'\n",
        " '0,' '0,' '1.0,' '0,' '1.0,' '0,' '-1.0,' '0,' '-1.0,' '0,' '0,' '1.0,'\n",
        " '0,' '0,' '-1.0,' '1.0,' '0,' '1.0,' '0,' '-1.0,' '0,' '1.0,' '0,' '-1.0,'\n",
        " '0,' '1.0,' '-1.0,' '0,' '0,' '-1.0,' '0,' '1.0,' '0,' '-1.0,' '0,' '0,'\n",
        " '-1.0,' '0,' '1.0,' '0,' '-1.0,' '0,' '1.0,' '0,' '0,' '1.0,' '0,' '0,'\n",
        " '0,' '0,' '1.0,' '0,' '0,' '-1.0,' '0,' '-1.0,' '0,' '-1.0,' '0,' '1.0,'\n",
        " '0,' '1.0,' '0,' '0,' '1.0,' '0,' '-1.0,' '0,' '-1.0,' '0,' '1.0,' '0,'\n",
        " '-1.0,' '0,' '1.0,' '0,' '-1.0,' '0,' '-1.0,' '0,' '-1.0,' '0,' '1.0,'\n",
        " '0,' '1.0,' '0,' '-1.0,' '0,' '0,' '1.0,' '0,' '-1.0,' '0,' '1.0,' '0,'\n",
        " '0,' '-1.0,' '1.0,' '0,' '0,' '-1.0,' '0,' '0,' '-1.0,' '0,' '-1.0,' '0,'\n",
        " '1.0,' '0,' '0,' '1.0,' '0,' '0,' '1.0,' '1.0,' '0,' '1.0,' '0,' '0,'\n",
        " '-1.0,' '0,' '0,' '-1.0,' '0,' '-1.0,' '0,' '0,' '-1.0,' '0,' '1.0,' '0,'\n",
        " '0,' '1.0,' '0,' '0,' '-1.0,' '0,' '1.0,' '0,' '1.0,' '0,' '0,' '1.0,'\n",
        " '0,' '-1.0,' '0,' '-1.0,' '0,' '0,' '1.0,' '0,' '-1.0,' '0,' '1.0,' '0,'\n",
        " '1.0,' '0,' '0,' '-1.0,' '0,' '0,' '1.0,' '0,' '-1.0,' '0,' '1.0,' '0,'\n",
        " '-1.0,' '0,' '0,' '-1.0,' '0,' '0,' '1.0,' '0,' '-1.0,' '0,' '0,' '-1.0,'\n",
        " '0,' '0,' '1.0,' '0,' '-1.0,' '0,' '0,' '1.0,' '0,' '0,' '1.0,' '0,' '0,'] ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
        " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
        " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
        " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
        " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
        " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
        " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
        " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '1'\n",
        " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
        " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
        " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
        " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
        " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
        " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
        " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
        " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '2' '2'\n",
        " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
        " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
        " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
        " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
        " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
        " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
        " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
        " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '3' '3'\n",
        " '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3'\n",
        " '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3'\n",
        " '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3'\n",
        " '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3'\n",
        " '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3'\n",
        " '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3'\n",
        " '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3'\n",
        " '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3']\n",
        "(457, 379)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(574, 379)\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "         -1       0.93      0.92      0.92       119\n",
        "          0       0.94      0.98      0.96       336\n",
        "          1       0.97      0.87      0.92       119\n",
        "\n",
        "avg / total       0.94      0.94      0.94       574\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAATQAAAFACAYAAAAyMoBIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x43d67d0>"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}